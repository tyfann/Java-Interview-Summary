预面试总结

java比较两个字符串是否相同应当使用a.euqals(b)而不能使用==，对于基础数据类型来说==判断的是两边的值是否相等，对于引用类型来说，==判断的是两边的引用是否相同，也就是判断两个对象是否指向了同一块内存区域，当使用场景是new String("a")这样new出字符串对象时，应当用equals()方法来比较内容而不能用==。如果两个字符串是这样String a="a"赋值方式时，同样也可以使用==来比较是否相等。
java比较语句中，通常把常量放在前面，原因：
（1）如果两个都是变量，那么无所谓谁先谁后
（2）如果一个是常量一个是变量，equals()方法是在Object类里定义的，也就是说任何对象都可以调用equals()方法，但是对象在调用方法的时候，如果对象为null那系统运行就会报空指针异常，显然这种异常是我们不愿看到的
HashMap不是线程安全的，并发情况会导致类似CPU占用100%等一些问题。而Hashtable虽然是线程安全的，但本身比较低效，因为它的实现基本就是将put、get、size等各种方法加上“synchronized”，这就导致了所有并发操作都要竞争同一把锁，一个线程在进行同步操作时，其他线程只能等待，大大降低了并发操作的效率。
一般hashtable的桶数会取一个素数，因为取合数时，都会不同程度在一些常见的引用中导致冲突。
但是取质数，可以在常见的应用中减少冲突几率。
ConcurrentHashMap:
数据结构：数组+链表+segment（java1.7）
数组+链表+红黑树+（Node/CAS）（java1.8）
红黑树、B+树
oss面试题

oss(Object Storage Service)对象存储，基于RESTful API

oss实现原理

Linux

Q：请你说说linux的内存管理

1，Linux为每个启动的进程在虚拟内存里开辟独立的空间。
2，虚拟内存由物理内存和交换空间构成。
3，linux将内存按组分成页面(pages)，linux会维护这个页面表，将一段时间不活动的页面放在交换空间里，将活动的页面放在物理内存里。当一个不活动的页面开始活动时，linux会从物理内存里为它腾出空间，将它从交换空间换入物理内存。

计算机网络TCP/IP
应用协议

运行在TCP协议上的协议：

HTTP（Hypertext Transfer Protocol，超文本传输协议），主要用于普通浏览
HTTPS（HTTP over SSL，安全超文本传输协议），HTTP协议的安全版本
FTP（File Transfer Protocol，文件传输协议），用于文件传输。
POP3（Post Office Protocol, version 3，邮局协议），收邮件用。
SMTP（Simple Mail Transfer Protocol，简单邮件传输协议），用来发送电子邮件。
TELNET（Teletype over the Network，网络电传），通过一个终端（terminal）登陆到网络。
SSH（Secure Shell，用于替代安全性差的TELNET），用于加密安全登陆用。
运行在UDP协议上的协议：

BOOTP（Boot Protocol，启动协议），应用于无盘设备。
NTP（Network Time Protocol，网络时间协议），用于网络同步。
DHCP（Dynamic Host Configuration Protocol，动态主机配置协议），动态配置IP地址。
运行在TCP和UDP协议上：

DNS（Domain Name Service，域名服务），用于完成地址查找，邮件转发等工作。
DNS工作原理：

第一步：客户机提出域名解析请求，并将该请求发送给本地的域名服务器。

第二步：当本地的域名服务器收到请求后，就先查询本地的缓存，如果有该纪录项，则本地的域名服务器就直接把查询的结果返回。

第三步：如果本地的缓存中没有该纪录，则本地域名服务器就直接把请求发给根域名服务器，然后根域名服务器再返回给本地域名服务器一个所查询域(根的子域) 的主域名服务器的地址。

第四步：本地服务器再向上一步返回的域名服务器发送请求，然后接受请求的服务器查询自己的缓存，如果没有该纪录，则返回相关的下级的域名服务器的地址。

第五步：重复第四步，直到找到正确的纪录。

第六步：本地域名服务器把返回的结果保存到缓存，以备下一次使用，同时还将结果返回给客户机。

传输协议

TCP协议
UDP协议
网际协议

IP协议
ICMP协议
ARP协议
路由控制协议

RIP协议
OSPF协议
BGP协议
运输层

TCP和UDP都在网络分层中的运输层

TCP是面向连接的可靠的服务，UDP是无连接的不可靠的服务

TCP三次握手过程：



Q：为什么握手就是三次而不是两次或者四次？
因为双方都需要彼此确认自己的发送能力没有问题，如果只握手两次那么client端可以确认自己的发送能力而server端就无法确认了；如果握手四次，显然是防止第三次握手丢失，第三次握手确实有可能会丢失，加入采用第四次来对第三次进行确认，那万一第四次也可能丢失则需要第五次来确认...这样来看可以发现无论是四次五次或是更多次效果都是一样的，这样的协议既不可能实现也没有任何效率可言。因此TCP采用了超时重传的策略来保证传输的可靠性。server在发送完第二次握手包之后就会开启一个定时器，超时前如果没有收到第三次握手包，它就会重新发送SYN+ACK，重复以上步骤，如果失败三次以上则说明连接失败，数据传输时采用同样的策略。

TCP四次挥手过程



Q：为什么断开连接需要四次挥手？
TCP连接是全双工通信的，而断开时双方都需要确定两个问题：自己是否还有数据要发送，对端是否还有数据要发送，而四次挥手正好在双方同步了这两个问题。

第一次挥手：client告诉server自己的数据已全部发送，client可以回收发送缓冲区，server可以回收接收缓冲区
第二次挥手：server告诉client自己收到了关闭信息
第三次挥手：server告诉client自己的数据已全部发送，server可以回收发送缓冲区，client可以回收接收缓冲区
第四次挥手：client告诉server自己收到了关闭信息
四次挥手同样一次都不能少，如果少了其中任何一次，总有一方不能可靠的通知对方自己的数据已发送完毕，因此连接不能可靠的断开，TCP也就成了不可靠的协议。

半连接攻击

半连接攻击是一种攻击协议栈的攻击方式，坦白说就是攻击主机的一种攻击方式。通过将主机的资源消耗殆尽，从而导致应用层的程序无资源可用，导致无法运行。在正常情况下，客户端连接服务端需要通过三次握手，首先客户端构造一个SYN连接数据包发送至服务端，自身进入SYN_SEND状态，当服务端收到客户端的SYN包之后，为其分配内存核心内存，并将其放置在半连接队列中，服务端接收客户SYN包并会向客户端发送一个SYN包和ACK包，此刻服务端进入SYN_RECV态。客户端收到包之后，再次向服务端发送ACK确认包。至此连接建立完成，双方都进入ESTABLSHEDZ状态。半连接就是通过不断地构造客户端的SYN连接数据包发向服务端，等到服务端的半连接队列满的时候，后续的正常用户的连接请求将会被丢弃，从而无法连接到服务端。此为半连接攻击方式。

如何解决半连接攻击？

可以通过拓展半连接队列的大小，来进行补救，但缺点是，不能无限制的增加，这样会耗费过多的服务端资源，导致服务端性能低下。这种方式几乎不可取。现在主要通过syn cookie或者syn中继机制来防范半连接攻击，部分半连接分配核心内存的方式来防范。

全连接攻击

全连接攻击是通过消费服务端进程数和连接数，只连接而不进行发送数据的一种攻击方式。当客户端连接到服务端，仅仅只是连接，此时服务端会为每一个连接创建一个进程来处理客户端发送的数据。但是客户端只是连接而不发送数据，此时服务端会一直阻塞在recv或者read的状态，如此一来，多个连接，服务端的每个连接都是出于阻塞状态从而导致服务端的崩溃。

如何来解决全连接攻击？

可以通过不为全连接分配进程处理的方式来防范全连接攻击，具体的情况是当收到数据之后，在为其分配一个处理线程。具体的处理方式在accept返回之前是不分配处理线程的。直到接收相关的数据之后才为之提供一个处理过程。例如在apache服务中，是通过预创建一定量的子进程作为处理连接继承。所有的自己进程都继承父进程的sockfd，每当有一个连接过来时，只有当accept返回是，才会为该链接分配一个进程来处理连接请求。负责，子进程一直处于等待状态。如果出现值是连接存在，而始终不放数据，该链接的状态是SYN_RECV，在协议栈中，提供一个保活期给该链接，如果超过保活期还没有数据到来，服务端协议栈将会断开该链接。如果没有该保活期，虽然避免了ESTABLESHED状态的数量，但是SYN_RECV的数据量的增长仍旧是不可估算的，所以需要利用保活期来监控该链接是需要清除断开。

Q：描述一下PING的过程？

首先假设A ping B
1.ping通知系统建立一个固定格式的ICMP请求数据包。
2.ICMP协议打包这个数据包和B的IP地址转交给IP协议层
3.IP层协议将机器B的IP地址为目的地址，本机的IP地址为源地址，加上一些头部必要的控制信息，构建一个IP数据包
4.获取B的MAC地址，做这个操作首先机器A会判断B是否在同一网段内，若IP层协议通过B的IP地址和自己的子网掩码，发现它跟自己属于同一网络，就直接在本网络查找这台机器的MAC，否则则通过路由器进行类似查找。
接下来是ARP协议根据IP地址查找MAC地址的过程:
若两台机器之前有过通信，在机器A的ARP缓存表里应该存有B的IP与其MAC地址的映射关系。
若没有，则通过发送ARP请求广播，得到回应的B机器MAC地址，并交给数据链路层
5.数据链路层构建一个数据帧，目的地址是IP层传过来的MAC地址，源地址是本机的MAC地址，再附加一些必要的控制信息，依据以太网的介质访问规则将他们传送出去
6.机器B收到这个数据帧后，先检查目的地址，和本机MAC地址对比：
符合，接受。接收后检查该数据帧。将IP数据包从帧中提取出来，交给本机的的IP地址协议层协议，IP协议层检查之后，将有用的信息提取给ICMP协议，后者处理，马上构建一个ICMP应答包，发送给A，其过程和主机A发送ICMP请求包到B的过程类似，但不用ARP广播收取A的信息，因为请求包中已经有足够的信息用于B回应A。
若不符合，丢弃

Q：PING用的是什么协议？

使用的是ICMP（”Internet Control Message Protocol“）协议，是TCP/IP协议族的一个子协议。

servlet不是线程安全的

在tomcat容器中，servlet默认是单例模式；如果实现ISingleThreadModule标记接口，则针对多个请求创建多个实例（最多20个），为了实现线程安全，可以：
1.使用局部变量，而不是实例变量
2.使用synchronized关键字

IO、阻塞IO（BIO）、非阻塞IO（NIO）

通常来说，IO操作包括：对硬盘的读写、对socket的读写以及外设的读写。

当用户线程发起一个IO请求操作（以读请求操作为例），内核会去查看要读取的数据是否就绪，对于阻塞IO来说，如果数据没有就绪，则会一直在那等待，知道数据就绪；对于非阻塞IO来说，如果数据没有就绪， 则会返回一个标志信息告知用户线程当前要读的数据没有就绪，当数据就绪之后，便将数据拷贝到用户线程，这样才完成了一个完整的IO读请求操作。

一个完整的IO读请求操作包括两个阶段：
1）查看数据是否就绪；
2）进行数据拷贝（内核将数据拷贝到用户线程）。

Docker

数据库
MySQL

MySQL有关权限的表：

user权限表：记录允许连接到服务器的用户账号信息（全局权限）
db权限表：记录在各数据库上的操作权限
table_priv权限表：记录数据表级的操作权限
columns_priv权限表：记录数据列级的操作权限
host权限表
MySQL的binlog（日志文件）录入格式：

statement模式：每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化。
row模式：不记录sql语句的上下文相关信息，仅保存哪条记录被修改（当表结构发生变化时，会记录语句而不是逐行记录）
mixed，折中方案，普通操作用statement，无法使用statement时用row。
MySQL存储引擎

存储引擎是MySQL中的数据、索引以及其他对象是如何存储的，是一套文件系统的实现。

常用存储引擎：

Innodb：提供了对数据库ACID事务的支持，提供了行级锁和外键的约束。设计目标即处理大数据容量的数据库系统。（索引组织表）
MyIASM：不提供事务的支持，也不支持行级锁和外键。（堆表）
MEMORY：所有数据都在内存中，数据的处理速度快，但安全性不高
Q：MyISAM索引和InnoDB索引的区别？

InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。
MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。
InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。
InnoDB引擎4大特性

插入缓冲
二次写
自适应哈希索引
预读
索引的基本原理：把无序的数据变成有序的查询

索引创建原则：

1）最左前缀匹配原则，联合索引中非常重要的原则，mysql会一直向右匹配知道遇到范围查询(>、<、between、like)就停止匹配，比如"a=1 and b=2 and c>3 and d=4"如果建立(a,b,c,d)顺序的索引则d是用不到索引的，如果建立(a,b,d,c)则都可以用到。

2）查询频繁的字段才去创建索引

3）更新频繁的字段不适合创建索引

4）区分度太低的列不适合做索引列

5）尽量扩展索引而不是新建索引

Q：如何删除百万级别以上的数据？

我们可以先删除百万数据的索引
然后删除其中无用的数据
删除完后再重新创建索引
与之前的直接删除比是要快速很多（更别说万一删除中断，则一切删除都会回滚）
Q：为什么联合索引遵循最左前缀匹配原则？
因为MySQL 建立联合索引的规则是这样的，它会首先根据联合索引中最左边的、也就是第一个字段进行排序，在第一个字段排序的基础上，再对联合索引中后面的第二个字段进行排序，依此类推。综上，第一个字段是绝对有序的，从第二个字段开始是无序的，这就解释了为什么直接使用第二字段进行条件判断用不到索引了（从第二个字段开始，无序，无法走 B+ Tree 索引）。

Q：慢sql语句原因？

索引命中

Q：性别适合用来做索引字段吗？为什么？

不适合。只有2种取值的字段,建了索引数据库也不一定会用,只会白白增加索引维护的额外开销,因为索引也是需要存储的,所以插入和更新的写入操作,同时需要插入和更新你这个字段的索引的，因此不适合做单列索引。

Q：什么情况下用单列索引？什么情况下用联合（级联）索引？

Q：索引的目的是什么？
快速访问数据表中的特定信息，提高检索速度
创建唯一性索引，保证数据库表中每一行数据的唯一性。
加速表和表之间的连接
使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间

索引在MySQL数据库中分四类：
B+树索引
Hash索引（不支持范围查找）
R-tree索引（空间索引）
全文索引

Hash索引等值查询效率高，但是不能排序，因此不能进行范围查询
B+树索引数据有序，能够进行范围查询

作为MySQL的数据库引擎之一，InnoDB存储引擎中主要用的是B+树索引。

B+树和B树的区别：
1、B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据
之所以这么做是因为数据库中页的大小是固定的，InnoDB中页的默认大小是16KB。如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘IO次数又会再次减少，数据查询的效率也会更快。
另外，B+树的阶数是等于键值的数量的，如果B+树一个节点可以存储1000个键值，那么3层B+树可以存储1000​1000​1000=10亿个数据。一般根节点是常驻内存的，所以一般我们查找10亿数据，只需要2次磁盘IO。

2、因为B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的。
那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。而B树因为数据分散在各个节点，要实现这一点是很不容易的。

聚集索引：以InnoDB作为存储引擎的表，以主键作为B+树索引的键值而构建的B+树索引，我们称之为聚集索引。

非聚集索引：以主键之外的列值作为键值构建的B+树索引，我们称之为非聚集索引。

B+树在满足聚簇索引和索引覆盖的时候不需要回表查询数据：

当查询使用聚簇索引时，在对应的叶子节点，可以获取到整行数据，因此不用再次进行回表查询。

Q：什么场景下适合使用索引？
1.当我们建立表的时候，默认已经将主键上建立唯一索引了
2.当某个字段频繁的作为查询参数，查询条件的字段也建议使用，比如号码（唯一，且查询频率高）
3.当使用join进行一个链表查询，就适合使用，外键也是一种查询条件频率高。
4.适合索引的列是出现在where子句中的列，或者连接子句中指定的列

Q：什么场景下不适合使用索引？
1.基数较小的类，索引效果较差，没有必要在此列建立索引
2.高频地增删改表的情况。这种表结构不建议使用索引

Q：索引缺点？
时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；
空间方面：索引需要占物理空间。

Q：为什么数据库索引不用红黑树而用B+树？
红黑树当插入删除元素的时候会进行频繁的变色与旋转（左旋，右旋），来保证红黑树的性质，浪费时间。但是当数据量较小，数据完全可以放入内存中，不需要进行磁盘IO，这时候，红黑树时间复杂度比B+树低。
比如TreeSet TreeMap 和HashMap （jdk1.8）就是使用红黑树作为底层数据结构。

Q：为什么不用二叉查找树作为数据库索引？
二叉查找树，查找到指定数据，效率其实很高logn。但是数据库索引文件有可能很大，关系型数据存储了上亿条数据，索引文件大则上G，不可能全部放入内存中，
而是需要的时候换入内存，方式是磁盘页。一般来说树的一个节点就是一个磁盘页。如果使用二叉查找树，那么每个节点存储一个元素，查找到指定元素，需要进行大量的磁盘IO，效率很低。
而B+树解决了这个问题，通过单一节点包含多个data，大大降低了树的高度，大大减少了磁盘IO次数。

每个数据库表可以建立多个索引，但是主索引只能建立1个。

索引失效

一般指联合索引查询时，不走索引

以下几种情况均会导致索引失效：

以A，B从左到右顺序建立联合索引，如果使用select * from xxx where A>100 and B<100是可以走索引的，但如果使用select * from xxx where B<100是不走索引的，因为遵循最左前缀法则，如果仅用B是不满足有序的条件的，B有序是建立在A相同的情况下才有序
在上述情况的基础上，如果使用select * from xxx where A>100 and B=100也是不走索引的
使用like语句需要使用前缀的字符串匹配"a%"而不是后缀"%a"或者中缀"%a%"，其他两种均会导致不走索引
数据库事务

概念：事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。（最经典的事务的例子：转账，小明转小红1000元，小明账户-1000，小红账户+1000。如果过程中由于系统崩溃而导致小明余额减少而小红余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都失败）

事务（本身不包含四个特性，但我们尽可能想达到这四个特性）四大特性（ACID）：

原子性A：满足原子操作单元，对数据的操作，要么全部执行，要么全部失败
一致性C：事务开始和完成，数据都必须保持一致
隔离型I：事务之间是相互独立的，中间状态对外不可见
持久性D：数据的修改是永久的
并发情况下事务引发的问题

脏读，幻读和不可重复读

脏读：某一事务已经更新了一份数据，而另一个事务与此同时读取了同一份数据，由于某些原因前一个事务回滚了操作，则后一个事务所读取的数据就会是不正确的。（破坏了隔离性）
幻读：在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列数据，而另一个事务与此同时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。（破坏了一致性，insert）
不可重复读：一个事务的两次查询数据不一致，可能是两次查询过程中插入了一个事务更新了原有的数据（破坏了一致性，update和delete）
解决并发情况下事务的矛盾

Q：讲讲mysql有几个事务隔离级别？
读未提交，读已提交（RC），可重复读（RR），串行化四个。MySQL默认是可重复读，而Oracle默认是读已提交。

读未提交（read-uncommitted）：最低一级，只能保证持久性
读已提交（read-committed）：语句级别的
可重复读（repeatable-read）：事务级别的
串行化（serializable）：最高级别，事务与事务完全串行化执行，毫无并发可言，性能极低
具体实现（以InnoDB为例）

锁机制：阻止其他事务对数据进行操作，各个隔离级别主要体现在读取数据时加的锁和释放时机。
RU：事务读取时候，不加锁
RC：事务读取时候加行级共享锁（读到才加锁），一旦读完，立刻释放（而不是事务结束）
RR：事务读取时候加行级共享锁，直到事务结束才会释放
SE：事务读取到加表级共享锁，直到事务结束时，才会释放
MVCC机制：生成一个数据快照，并用这个快照来提供一定级别的一致性的读取，也成为了多版本数据控制。
实际上就是CAS版本控制和读写分离的思想
主要作用于RC和RR级别
Q：为什么mysql选可重复读作为默认的隔离级别？
在RR级别下，binlog为任何格式均不会造成主从数据不一致的情况出现，但当低版本MySQL使用RC+STATEMENT组合时（MySQL5.1.5前只有statement格式）将会导致主从数据不一致。解决这个问题可以采用RC+ROW组合的方式

Q：项目中为什么不用读未提交（RC）和串行化（Serializable）两个隔离级别？
1.采用读未提交（RC），一个事务读到另一个事务未提交读数据，从逻辑上都说不过去
2.采用串行化（Serializable），每次读操作都会加锁，快照读失效，一般是使用mysql自带分布式事务功能时才使用该隔离级别

Q：在RC级别下，主从复制用什么binlog模式？
用的binlog为row格式，是基于行的复制。

Q：为什么互联网项目用读已提交（RC）这个隔离级别？
在RC级别下，不可重复读问题需要解决吗？不用解决，这个问题是可以接受的。毕竟数据都已经提交了，读出来本身就没有太大问题。Oracle的默认隔离级别就是RC，原因：
1、在RR隔离级别下，存在间隙锁，导致出现死锁的几率比RC大的多
2、在RR隔离级别下，条件列未命中索引会锁表。而在RC隔离级别下，只锁行

锁

当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。

Q：按照锁的粒度来分数据库锁有哪些？

分为行级锁（InnoDB引擎）、表级锁（MyISAM引擎）和页级锁（BDB引擎）

行级锁：开销大，加锁慢，会出现死；锁定粒度最小，发生锁冲突概率最低，并发读最高
表级锁：实现简单，消耗资源少；锁定粒度最大
页级锁：锁粒度介于行级锁和表级锁中间的一种锁。是一种折中方案
Q：按照锁的类别来分数据库锁有哪些？

共享锁（s锁）和排他锁（x锁）

InnoDB引擎的行锁是基于索引来完成的。

死锁

概念：死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。

Q：如何解决死锁？

如果不同程序并发存取多个表，尽量约定以相同的顺序访问表
在同一个事务中，尽可能做到一次锁定所需要的所有资源
对于非常容易产生死锁的业务部分，可以尝试升级锁定粒度，通过表级锁定来减少死锁产生的概率
statement、prepareStatement的用法和解释

PreparedStatement是预编译的,对于批量处理可以大大提高效率. 也叫JDBC存储过程
使用 Statement 对象。在对数据库只执行一次性存取的时侯，用 Statement 对象进行处理。PreparedStatement 对象的开销比Statement大，对于一次性操作并不会带来额外的好处。
statement每次执行sql语句，相关数据库都要执行sql语句的编译，preparedstatement是预编译得, preparedstatement支持批处理
总结：批量处理SQL语句用PreparedStatement，单次处理用Statement可以减少开销

六种关联查询

交叉连接（cross join）
内连接（inner join）
外连接（left join/right join）
联合查询（union和union all）
全连接（full join）（MySQL不支持全连接，可以使用LEFT JOIN 和UNION和RIGHT JOIN联合使用）
左外连接（left join），以左表为主，先查询出左表，按照on后的关联条件匹配右表，右外连接同理

Q：Union和Union all有什么区别？

Union：对两个结果集进行并集操作，不包括重复行（相当于distinct），同时进行默认规则的排序；
Union All：对两个结果集进行并集操作，包括重复行，不进行排序；
不去重情况下Union All效率高于Union

Q：MySQL中in和exists的区别？

mysql的in语句是把外表和内表作hash连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。其中

如果查询的两个表大小相当，那么用in和exists差别不大
如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in
not in和not exists：查询语句中not in没有用到索引而not exists子查询依然能用到表上的索引。所以无论哪个表大，用not exists都比not in要快。
Q：varchar和char的区别？

性能角度来说char更快，节省磁盘空间角度varchar更小。

Q：drop、delete和truncate的区别？

不再需要一张表的时候，用drop；想删除部分数据行时候，用delete；保留表而删除所有数据的时候用truncate

SQL的生命周期

应用服务器与数据库服务器建立一个连接
数据库进程拿到请求sql
解析并生成执行计划，执行
读取数据到内存并进行逻辑处理
通过步骤1的连接，发送结果到客户端
关闭连接，释放资源
MySQL复制原理及流程

主从复制：将主数据中的DDL和DML操作通过二进制日志（BinLog）传输到从数据库上，然后将这些日志重新执行（重做）；从而使得从数据库的数据与主数据库保持一致。

主从复制的作用：

主数据库出现问题，可以切换到从数据库。
可以进行数据库层面的读写分离
可以在从数据库上进行日常备份
主从复制解决的问题：

数据分布
负载均衡
高可用和故障切换
升级测试
Redis

Q：Redis支持的数据类型？

1、string类型是Redis最基本的数据类型，一个键最大能存储512MB
2、Hash，Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象
3、List
4、Set
5、zset（sorted set：有序集合）

Q：什么是Redis持久化？Redis有哪几种持久化方式？优缺点是什么？

持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。

持久化方式包括RDB（Redis DataBase）、AOF（Append-only file）

存储结构：内容是redis通讯协议（RESP）格式的命令文本存储

比较：AOF相比于RDB的优点：AOF的更新频率高，优先使用AOF还原数据，AOF更安全也更大
RDB的优点：性能比AOF好
总结：如果两个都配了优先加载AOF

RDB

概念：在规定的时间间隔之内将内存中的数据集快照写入磁盘，redis会单独创建（fork）一个与当前进程一模一样的子进程来进行持久化，这个子线程的所有数据（变量，环境变量，程序计数器等）都和原进程一模一样，会先将数据写入到一个临时文件中，待持久化结束了，再用这个临时文件替换上次持久化好的文件，整个过程中，主进程不进行任何io操作，这就确保了极高的性能。（类似于快照形式）

优点：相比较于aof而言：rdb比较节省磁盘空间，只保持更新整个redis缓存中所有数据的一个完整性。即相当于一定的时间间隔内对redis缓存数据进行一个持久化操作，采取一种临时文件替换上一层保存的文件，比较节省空间。

缺点：每一次fork redis中全部数据的时候，会因数据量的增加而增加性能的消耗。周期性进行备份的时候，如果突然停止，就会丢失最后一次快照的修改。临时文件会丢失。

AOF

概念：将redis的操作日志以追加的方式写入文件，不记录读操作，恢复的时候将操作信息对着原有数据执行一遍，把最新数据写回redis中。

优点：备份机制更加成熟稳健，对每一条操作都可以直接持久化文件，大大降低丢失率；同时可以对其进行人为的操作

缺点：粒度细致，只增加数据而不修改数据，因此会占用更多的磁盘空间，同时也因为粒度细，反操作的时候会造成性能压力。

触发机制

no：表示等操作系统进行数据缓存同步到磁盘（快，持久化没保证）
always：同步持久化，每次发生数据变更时，立即记录到磁盘（慢，安全，浪费性能）
everysec：表示每秒同步一次（默认值，很快，但可能会丢失一秒以内的数据变更日志）
Q：解释一下什么是RESP？有什么特点？

RESP是redis客户端和服务端之间使用的一种通讯协议；

RESP特点：实现简单、快速解析、可读性好

Q：Redis有哪些架构模式？讲讲各自的特点

单机版：
特点：简单
问题：1、内存容量有限 2、处理能力有限 3、无法高可用

主从复制：
特点：1、master/slave 角色 2、master/slave 数据相同 3、降低master读压力在转交从库
问题：1、无法保证高可用 2、没有解决master写的压力

Q：谈谈redis分片时的Hash一致性算法？为什么会用到这种算法？

产生背景：使用redis的分片操作后，数据会落入不同的redis节点中，那么数据存储的规则是什么？

Q：Redis为什么快？

A：首先，采用了多路复用io阻塞机制
然后，数据结构简单，操作节省时间
最后，运行在内存中，自然速度快

Q：为什么Redis是单线程的？

A：Redis官方很敷衍就随便给了一点解释。不过基本要点也都说了，因为Redis的瓶颈不是cpu的运行速度，而往往是网络带宽和机器的内存大小。再说了，单线程切换开销小，容易实现既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。

Q：常见的NoSQL（非关系型）数据库有哪些？特性是什么？

A：NoSQL分为列式数据库、K-V数据库、文档型数据库、全文搜索引擎、图形数据库

常见的列式数据库：HBase，BigTable。
优点：高效的存储空间利用率（普通的行式数据库一般压缩率在3:1到5:1左右，而列式数据库的压缩率一般在8:1到30:1左右）、查询效率高、适合做聚合操作、适合大量的数据而不是小数据；
缺点：不适合扫描小量数据、不适合随机的更新、不适合做含有删除和更新的实时操作
应用场景：以HBase为例：适合大数据量（100TB级数据），有快速随机访问的需求；适合写密集型应用，写入量大而读数量相对较小的应用；对性能和可靠性要求非常高的应用；适合数据量较大且增长量无法预估的应用，需要进行优雅的数据扩展的应用。HBase支持在线扩展，即使在一段时间内，数据量呈井喷式增长，也可以通过HBase横向扩展来满足功能。

常见的K-V数据库：Redis，Cassandra，Memchached。以Redis为例，
优点：性能极高、丰富的数据类型、丰富的特性；
缺点：Redis事务不能支持原子性和持久性（Atomicity，Durability），只支持隔离性和一致性（Isolation，Consistency）
应用场景：存储用户信息（比如会话）、配置文件、参数、购物车等等
不适用的场景：不适合需要支持事务的场景。在K-V数据库中故障产生时不可以进行回滚。

常见的文档型数据库：MongoDB，CouchDB。以MongoDB为例，
优点：容易存储复杂数据。JSON 是一种强大的 描述语言，能够描述复杂的 数据结构；
缺点：主要是对 多条数据记录 的 事务支持较弱；

缓存雪崩

概念：大量的缓存key，在同一时间大量的失效

缓存穿透

概念：redis中没有请求所需要的数据，请求就会直接穿过redis到数据库

缓存击穿

概念：某一个非常热点的key，大量的用户去请求这个缓存key，当缓存key突然失效的时候，这些请求都会打到数据库上，可能导致数据库挂掉

解决方案：

布隆过滤器
分布式锁，只允许单线程访问数据库，返回的结果重新写入redis缓存中，其他的线程等待几ms，然后重新从redis中读取。
让redis集群中的缓存过期时间设置成随机时间，而不是同一时间全部失效
设置某一个时间区间过后重新更新过期缓存
分布式锁

业务场景：互联网公司秒杀业务（高并发分布式场景）

开发框架：redisson（lock(), unlock()）

问题：如果Redis采取主从复制的结构，在一个线程对于redis上锁了之后，主redis尚未将lockkey复制到从redis就挂了，后续的redis重新选出的master节点没有lockkey，导致后续线程会直接得到锁，此类问题如何解决？

redlock
zookeeper分布式锁概念（分布式一致性问题，采用leader选举手段）（能解决问题，但性能不如redis）
并发编程
并发编程优缺点

Q：为什么要使用并发编程？（并发编程的优点）

充分利用多核CPU的计算能力：通过并发编程的形式可以将多核CPU的计算能力发挥到极致，提升性能
方便进行业务拆分，提升系统并发能力和性能。现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。
面对复杂业务模型，并发程序会比串行程序更适应业务需求，而并发编程更能吻合这种业务拆分。
并发编程三要素（线程的安全性问题体现在）：

原子性（atomic）：指一个或多个操作要么全部执行成功要么全部执行失败；
可见性：一个线程对共享变量的修改，另一个线程能够立刻看到。（synchronized, volatile）
有序性：程序执行的顺序按照代码先后顺序执行（处理器可能会对指令重排序）
出现线程安全问题的原因：

线程切换带来的原子性问题
缓存导致的可见性问题
编译优化带来的有序性问题
解决手段：

解决原子性问题：JDK Atomic开头的原子类、synchronized、LOCK
解决可见性问题：synchronized、volatile、LOCK
解决有序性问题：Happens-Before规则
Q：并发和并行有什么区别？

并发：多个任务在同一个CPU核上，按细分的时间片轮流（交替）执行，从逻辑上来看那些任务是同时执行。
并行：单位时间内，多个处理器或者多核处理器同时处理多个任务，是真正意义上的“同时进行”。
串行：有n个任务，由一个线程按顺序执行。由于任务、方法都在一个线程执行所以不存在线程不安全的情况
形象比喻：
并发 = 两个队列+一台咖啡机
并行 = 两个队列+两台咖啡机
串行 = 一个队列+一台咖啡机

多线程

java本身无法开启新的线程，需要调用native本地方法，也就是底层的c++，java无法直接操作硬件
概念：多线程是指程序中包含多个执行流，即在一个程序中可以同时运行多个不同的线程来执行不同的任务

优势：

可以提高CPU的利用率。在多线程程序中，一个线程必须等待的时候，CPU可以运行其他线程而不是等待，这样就大大提高了程序效率。也就是允许单个程序创建多个并行执行的线程来完成各自的任务。

劣势：

线程也是程序，所以线程需要占用内存，线程越多内存占用也越多
多线程需要协调和管理，所以需要CPU时间跟踪线程
线程之间对共享资源的访问会相互影响，必须解决竞争共享资源的问题
进程与线程的区别：

一个进程可以有多个线程，每一个在内存中运行的应用程序就是进程；多个线程之间可以共享数据

上下文切换

概念：多线程编程中一般线程的个数大于CPU核心的个数，而一个CPU核心在任意时刻只能被一个线程使用，当前任务在执行完CPU时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载到过程就是一次上下文切换。

上下文切换对系统来说意味着消耗大量的CPU时间。事实上，可能是操作系统中时间消耗最大的操作。

Linux相比其他操作系统有很多优点，其中一项就是Linux上下文切换和模式切换的时间消耗非常少。

守护线程与用户线程

用户（User）线程：运行在前台，执行具体的任务
守护（Daemon）线程：运行在后台，为其他前台线程服务。一旦所有用户线程都结束运行，守护线程会随JVM一起结束工作
线程死锁

比如线程A持有资源2，线程B持有资源1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。

形成死锁的四个必要条件：

互斥条件：
请求与保持条件
不剥夺条件
循环等待条件
如何避免线程死锁？

只需要破坏产生死锁的四个条件中的其中一个就可以了。

互斥条件（锁的目的就是用来互斥的）无法破坏，因此只能破坏其他三个条件。

破坏请求与保持的条件：一次性申请所有的资源
破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源
破坏循环等待条件：靠按序申请资源来预防。

创建线程的方式

四种方式：

继承Thread类；
实现Runnable接口；
实现Callable接口；
使用Executors工具类创建线程池
Q：说一下runnable和callable的区别？

相同点：

都是接口
都可以编写多线程程序
都采用Thread.start()启动线程
区别：

Runnable接口run方法无返回值；Callable接口call方法有返回值，是个泛型，和Future、FutureTask配合可以用来获取异步执行的结果
Runnable接口run方法只能抛出运行时异常，且无法捕获处理；Callable接口call方法允许抛出异常，可以获取异常信息
Q：线程的run()和start()有什么区别？

start()方法用于启动线程，run()方法用于执行线程的运行时代码。run()可以重复调用，而start()只能调用一次。

Q：既然调用start()方法会执行run()方法，为什么我们不能直接调用run()方法？

调用start()方法方可启动多线程工作，而直接调用run()方法只是thread的一个普通方法调用，还是在主线程里执行。

Future

Future接口表示异步任务，是一个可能还没有完成的异步任务的结果。Callable用于产生结果而Future用于获取结果。

FutureTask：

FutureTask表示一个异步运算的任务。FutureTask里面可以传入一个Callable的具体实现类。其中get方法可以获取Callable中的返回值，如果运算尚未完成get方法将阻塞。由于FutureTask也是Runnable接口的实现类，所以FutureTask也可以放入线程池中。

线程的生命周期

五种基本状态：

新建（new）：新创建了一个线程对象
可运行（runnable）：线程对象创建后，当调用线程对象的start()方法，该线程处于就绪状态，等待被线程调度选中，获取CPU的使用权
运行（running）：可运行状态(runnable)的线程获得了CPU时间片(timeslice)，执行程序代码。（线程要想进入运行状态执行，首先必须处于就绪状态(runnable)中）
阻塞（block）：处于运行状态中的线程由于某种原因，暂时放弃对CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才有机会再次被CPU调用以进入running状态。
阻塞分三种情况：
1）等待阻塞：wait()方法
2）同步阻塞：synchronized方法
3）其他阻塞：sleep()或join()或I/O请求
死亡（dead）：线程run()、main()方法执行结束，或因异常退出了run()方法，则该线程生命周期结束。死亡的线程不可再次复生
线程调度

线程调度算法：

两种调度模型：分时调度模型和抢占调度模型。

分时调度模型是指让所有的线程轮流获得CPU的使用权，并且平均分配每个线程占用的CPU的时间片
抢占调度模型（JVM采取的模型）是指优先让runnable池中优先级高的线程占用CPU，如果runnable池中的线程优先级相同，那么就随机选择一个线程，使其占用CPU。处于running状态的线程会一直运行，直到它不得不放弃CPU。
发生以下情况，就会终止线程的运行：

（1）线程体中调用了yield方法

（2）线程体中调用了sleep方法

（3）线程由于IO操作受到阻塞

（4）另外一个更高优先级线程出现

（5）在支持时间片的系统中，该线程的时间片用完

Q：线程同步和线程调度有哪些方法？

wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁；
sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法需要处理InterruptedException异常；
notify()：唤醒一个处于等待状态的线程，调用此方法并不能明确唤醒某一个，而是由JVM确定唤醒哪个线程，且与优先级无关；
notifyAll()：唤醒所有处于等待状态的线程，让所有线程竞争锁
Q：wait()方法调用是用if语句还是用循环？为什么？

应该在循环中调用，因为当线程获取到CPU开始执行的时候，其他条件可能还没有满足，所以采用循环检测条件是否满足会比较好

Q：如何停止一个正在运行的线程？

使用退出标志，使线程正常退出，也就是当run方法完成后线程终止
使用stop方法强行终止（不推荐，过期作废）
使用interrupt方法中断线程
Q：如何在两个线程间共享数据？

共享变量即可实现共享

java线程通信协作

常见的两种方式：

synchronized加锁的线程Object类的wait()/notify()/notifyAll()
ReentrantLock类加锁的线程的Condition类的await()/signal()/signAll()
Q：什么是线程安全？

线程安全是指某个方法在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。

Q：什么是线程优先级？

每一个线程都有优先级，高优先级线程在运行时会具有优先权。
Java的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，除非特别需要，一般无需设置线程优先级。

synchronized

作用：synchronized关键字是用来控制线程同步的，在多线程的环境下，控制synchronized代码段不被多个线程同时执行。synchronized可以修饰类、方法、变量。

Java早期版本中，synchronized属于重量级锁，效率低下，在java6以后官方从JVM层面对synchronized进行了较大优化，引入了如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

synchronized关键字最主要的三种使用方式：

修饰实例方法：作用于当前对象实例加锁
修饰静态方法：给当前类加锁
修饰代码块：指定加锁对象，对给定对象加锁
synchronized可重入原理：

重入锁是指一个线程获取到该锁之后，该线程可以继续获得该锁。底层原理维护一个计数器，当线程获取该锁时，计数器加一，再次获得该锁时继续加一，释放锁时，计数器减一，当计数器值为0时，表明该锁未被任何线程所持有，其他线程可以竞争获取锁。

自旋锁

由于很多synchronized里面的只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态之间切换的问题。可以让等待的线程在synchronized的边界做忙循环。如果做了多次循环发现还没有得到锁，再阻塞可能是一种更好的策略。

多线程中synchronized锁升级的原理是什么？

在锁对象的对象头里有一个threadId字段，在第一次访问的时候threadId为空，jvm让其持有偏向锁，并将threadId设置为其线程id，再次进入的时候会先判断threadId是否与其线程id一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数后如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了synchronized锁的升级。（偏向锁（设置threadId=id）----->（如果threadId!=id）轻量级锁------->（自旋一定次数仍没有获取到要使用的对象）重量级锁）

锁升级的目的是什么？

减低锁带来的性能消耗。

Q：线程B如何知道线程A修改了变量？

volatile修饰变量
synchronized修饰修改变量的方法
wait/notify
while轮询
Q：synchronized和ReentrantLock区别是什么？

相同点：两者都是可重入锁（自己可以再次获取自己的内部锁）

主要区别：

synchronized是关键字，而ReentrantLock是类，这是二者的本质区别。
ReentrantLock必须手动获取与释放锁，而synchronized不需要手动开启和释放锁
ReentrantLock只适用于代码块锁，而synchronized可以修饰类、方法、变量等
普通同步方法，synchronized锁的是当前实力对象
静态同步方法，synchronized锁的是当前类的class对象
同步方法快，synchronized锁的是括号里的对象

volatile

作用：volatile关键字用来保证可见性和禁止指令重排。volatile提供happens-before的保证，确保一个线程的修改能对其他线程是可见的。当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。

volatile常用于多线程环境下的单次操作（单次读或者单次写）

Q：volatile变量和atomic变量的区别？

volatile可以确保先行关系但不保证原子性；而atomic可以保证原子性

虽然volatile只能保证可见性不能保证原子性，但用volatile修饰long和double可以保证其操作原子性。

volatile 表示变量在 CPU 的寄存器中是不确定的，必须从主存中读取。保证多线程环境下变量的可见性；禁止指令重排序。

Q：volatile和synchronized区别？

volatile是变量修饰符（只能修饰变量）；synchronized可以修饰类、方法、变量。
volatile仅能实现变量的修改可见性，不保证原子性；而synchronized可以保证变量的修改可见性和原子性。
volatile不会造成线程阻塞；synchronized可能会造成线程的阻塞。
volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字好。
使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。

CAS

CAS（compare and swap），即比较交换，是一种乐观锁。乐观锁采取一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加version来获取数据。

CAS操作包含三个操作数——内存位置（V）、预期原值（A）和新值（B）。如果内存地址里面的值和A的值是一样的，那么就将内存里面的值更新成B。

Q：CAS会产生什么问题？

ABA问题：比如，老板准备搞促销，给店里所有会员卡上额度低于20元的会员都充值10元，程序员小王采用CAS的方式，将每个用户余额包装成AtomicInteger，写一个判断开启10个线程，然后判断小于20的一律加10。结果一段时间后发现，明明原先会员只有100个左右，全部充值10元也只要1000元上下，账面却亏损了2000甚至更多，原因是发现有许多客户被充值了10次。（原因：线程A去判断账户里的钱是15元，满足条件，直接+10，这时候卡上余额是25，但此时恰好这个客人在店内消费了10元，卡上余额又为15，线程B去执行扫描账户的时候，发现它又小于20，又用CAS给它加了10，这样的话就相当于加了2次）
循环时间长开销大：对于资源竞争严重（线程冲突严重）的情况下，CAS自旋的概率比较大，从而浪费更多CPU的资源，效率低于synchronized。
只能保证一个共享变量的原子操作：当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但对于多个共享变量操作时，循环CAS无法保证操作的原子性，这个时候可以用锁
ThreadLocal

概念：ThreadLocal是一个本地线程副本变量工具类，在每个线程中都创建了一个ThreadLocalMap对象，简单来说ThreadLocal就是一种以空间换时间的做法，每个线程可以访问自己内部ThreadLocalMap对象内的value。通过这种方式，避免资源在多线程间共享。

原理：线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java提供ThreadLocal类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如Web服务器）使用线程局部变量的时候要注意工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java应用就存在内存泄漏的风险。

线程局部变量

概念：线程局部变量就是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java提供ThreadLocal类来支持线程局部变量，是一种实现线程安全的方式。

但如果在管理环境中一旦工作完成后没有释放线程局部变量，Java应用就存在内存泄漏的风险。

Q：为什么ThreadLocal会造成内存的泄漏？

ThreadLocalMap中使用的key为ThreadLocal的弱引用，而value是强引用。所以，如果ThreadLocal没有被外部强引用的情况下，在垃圾回收的时候key会被清理掉，而value不会被清理掉。这样一来，ThreadLocalMap中就会出现key为null的Entry。假如我们不做任何措施的话，value永远无法被GC回收，这个时候就可能产生内存泄漏。使用完ThreadLocal方法后，最好手动调用remove()方法。

Q：如何解决ThreadLocal造成内存泄漏？

每次使用完ThreadLocal都调用它的remove()方法，清理数据（在使用线程池的情况下如果没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的可能导致业务逻辑出现问题，因此使用完就要清理）
演示代码：


1
public class TestThreadLocal {
2
    private static final ThreadLocal<Integer> THREAD_LOCAL_NUM
3
            = new ThreadLocal<Integer>(){
4
        @Override
5
        protected Integer initialValue() {
6
            return 0;
7
        }
8
    };
9
    public static void main(String[] args) {
10
        for (int i = 0; i < 3; i++){
11
            new Thread(()->{
12
                add10ByThreadLocal();
13
            }).start();
14
        }
15
    }
16
​
17
    private static void add10ByThreadLocal() {
18
        for (int i = 0; i < 5; i++){
19
            Integer n = THREAD_LOCAL_NUM.get();
20
            n += 1;
21
            THREAD_LOCAL_NUM.set(n);
22
            System.out.println(Thread.currentThread().getName() + " : ThreadLocal num = "+ n);
23
            THREAD_LOCAL_NUM.remove();
24
        }
25
​
26
    }
27
}
阻塞队列（BlockingQueue）

线程池

Q：为什么需要线程池？（池化概念的来源）

池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。

Spring
Spring框架的核心：IoC容器和AOP模块。通过IoC容器管理POJO（Plain Ordinary Java Object，简单普通的java对象）对象以及他们之间的耦合关系；通过AOP以动态非侵入的方式增强服务。

IoC让相互协作的组件保持松散的耦合，而AOP编程允许你把遍布于应用各层的功能分离出来形成可重用的功能组件。

Spring优点：

方便解耦，简化开发
AOP面向切面编程，可以方便地对程序进行权限拦截、运行监控等功能
声明式事务的支持
对Junit4支持，方便程序的测试
方便集成各种优秀框架
降低JavaEE API的使用难度
Spring框架中涉及的设计模式

工厂模式：BeanFactory
单例模式：Bean默认为单例模式
代理模式：AOP用到了JDK的动态代理和CGLIB字节码生成技术
模版方法：用来解决代码重复的问题。比如RestTemplate
观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新
IoC

控制反转即IoC（Inversion of Control），它把传统上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。所谓的“控制反转”概念就是对组件对象控制权的转移，从程序代码本身转移到了外部容器。

所谓的控制反转指的就是把程序控制的主动权由程序员转变为用户

Spring通过IoC（Inversion of Control）容器实现对象耦合关系的管理，并实现依赖反转，将对象之间的依赖关系交给IoC容器，实现解耦；

IoC的作用

管理对象的创建和依赖关系的维护。在对象关系比较复杂的时候，如果靠程序员来维护依赖关系是相当困难的
解耦，由容器去维护具体的对象
托管了类的产生过程
IoC的优点

IoC或依赖注入把应用的代码量降到最低
让应用更容易测试
IoC容器支持加载服务时的饿汉式初始化和懒加载
BeanFactory和ApplicationContext的关系：

BeanFactory简单粗暴，可以理解为一个HashMap，Key是BeanName，Value是Bean实例。通常只提供注册（put）和获取（get）这两个功能。我们可以称之为“低级容器”。

ApplicationContext可以称之为“高级容器”。因为它继承了多个接口。该接口定义了一个refresh方法，用于刷新整个容器，即重新加载/刷新所有的bean。

IoC在Spring里，只需要低级容器就可以实现，2个步骤：

加载配置文件，解析成BeanDefinition放在Map里
调用getBean的时候，从BeanDefinition所属的Map里，拿出Class对象进行实例化，同时如果有依赖关系，将递归调用getBean方法——完成依赖注入。
Spring Beans

概念：Spring bean 表示受到Spring管理的对象。具体说来，它是被Spring框架容器初始化、配置和管理的对象。Spring bean是在Spring的配置文件中定义（现在也可以通过annotation注解来定义），在Spring容器中初始化，然后注入到应用程序中的。

Spring框架中bean的五种作用域：

singleton：bean在每个Spring ioc容器中只有一个实例
prototype：一个bean的定义可以有多个实例
request：每个http请求都会创建一个bean
session：在一个HTTP Session中，一个bean定义对应一个实例
global-session：在一个全局的HTTP Session中，一个bean定义对应一个实例
Spring bean在缺省情况下作用域是singleton。使用prototype作用域需要慎重的思考，因为频繁创建和销毁bean会带来很大的性能开销。

Q：Spring框架中的单例（singleton）bean是线程安全的吗？

不是，Spring框架中的单例bean不是线程安全的。
Spring框架并没有对单例bean进行多线程的封装处理。
如果需要开发者自行去保证线程安全的情况，最简单的方法就是改变bean的作用域，把singleton改成prototype，这样请求bean相当于new Bean()了，也就保证了线程安全

Spring处理线程并发问题：

ThreadLocal和线程同步机制（synchronized）都是为了解决多线程中相同变量的访问冲突问题。同步机制是”时间换空间“，仅提供一份变量，而ThreadLocal是”空间换时间“，为每一个线程提供一个独立的变量副本，从而隔绝了多个线程对数据的访问冲突。

AOP

Spring MVC
Spring MVC 的原理和流程

SpringMVC执行流程:
 1.用户发送请求至前端控制器DispatcherServlet
 2.DispatcherServlet收到请求调用处理器映射器HandlerMapping。
 3.处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。
 4.DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作
 5.执行处理器Handler(Controller，也叫页面控制器)。
 6.Handler执行完成返回ModelAndView
 7.HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet
 8.DispatcherServlet将ModelAndView传给ViewReslover视图解析器
 9.ViewReslover解析后返回具体View
 10.DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。
 11.DispatcherServlet响应用户。

JavaWeb
基本概念：包括了动态web和静态web

静态web：

html
css
动态web：

ASP
JSP/Servlet
php
Web相关技术

ASP

微软：国内最早流行的就是ASP
在HTML中嵌入了VB的脚本，ASP+COM；
在ASP开发中，基本一个页面都有几千行的业务代码，页面极其混乱
维护成本高
C#
IIS（Internet Information Services）
php

PHP开发速度很快，功能很强大，跨平台，代码很简单
无法承载大访问量的情况（局限性）
JSP/Servlet

sun公司主推的B/S（浏览器和服务器）架构
基于Java语言的
可以承载三高（高并发、高可用、高性能）问题带来的影响；
Web服务器

概念：服务器是一种被动的操作，用来处理用户的一些请求和给用户一些响应信息；

IIS

微软的ASP，Windows自带的
Tomcat

免费开源的Web应用服务器，属于轻量级应用服务器，对于Java初学Web的人来说，它是最佳的选择
Tomcat实际上运行JSP页面和Servlet
Q：谈谈网站是如何进行访问的？

输入一个域名（www.baidu.com），回车
检查本地的hosts配置文件中有没有这个域名的映射
有：直接返回对应的ip地址，这个地址中有我们需要访问的web程序，可以直接访问
没有：没有：去DNS服务器找，向上递归根目录找映射，找不到就返回找不到
Http

概念：Http（超文本传输协议）是一个简单的请求响应协议，它通常运行在TCP之上

文本：html，字符串，...
超文本：图片，音乐，视频，定位，地图...
默认端口号：80

HTTPS：SecureSocket安全的

默认端口号：443

两个时代

http1.0
HTTP/1.0：客户端可以与web服务器连接后，只能获得一个web资源，断开连接
http2.0
HTTP/1.1：客户端可以与web服务器连接后，可以获得多个web资源
Http请求

客户端---发请求---服务器
百度：


1
Request URL: https://www.baidu.com/
2
Request Method: GET
3
Status Code: 200 OK
4
Remote Address: 110.242.68.4:443
5
Referrer Policy: strict-origin-when-cross-origin

1
Accept: text/html
2
Accept-Encoding: gzip, deflate, br
3
Accept-Language: zh,zh-TW;q=0.9,en-US;q=0.8,en;q=0.7,zh-CN;q=0.6
4
Cache-Control: max-age=0
5
Connection: keep-alive
Http响应

服务器---响应---客户端
百度：


1
Cache-Control: private
2
Connection: keep-alive
3
Content-Encoding: gzip
4
Content-Type: text/html;charset=utf-8
请求行

请求行中的请求方式：GET
请求方式：GET，POST，HEAD，DELETE，PUT，TRACT
get：请求能够携带的参数比较少，大小有限制，会在浏览器的URL地址栏显示数据内容，不安全，但高效
post：请求能够携带的参数没有限制，大小没有限制，不会在浏览器的URL地址栏显示数据内容，安全，但不高效
Servlet

简介

Servlet就是sun公司开发动态web的一门技术
Sun在这些API中提供一个接口叫做：Servlet，如果想要开发一个Servlet程序，只需要完成两个小步骤：
编写一个类，实现Servlet接口
把开发好的Java类部署到web服务器中
把实现了Servlet接口的Java程序叫做Servlet

Java基础知识面试题
面向对象的三大特性

封装
继承
多态
所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。
Java实现多态有三个必要条件：继承、重写、向上转型
多态详解

多态就是一个类的多种形式

编译时多态（静态多态）（程序在编译时就知道调用了哪个方法）
编译期间决定目标方法
通过overloading重载实现
方法名相同，参数不同（函数重载）
运行时多态（动态多态）（程序在运行时才知道调用了哪个方法）
运行期间决定目标方法
同名同参（运行时才决定目标方法而不是编译时）
overriding和继承实现
JVM决定目标方法（类加载机制，双亲委派）
生产者消费者模型

用一句话概括，生产者消费者模型必须具有的条件是三种关系，两类角色，一类交易场所。
一类交易场所：交易场所指的是生产者和消费者之间进行数据交换的仓库，这块仓库相当于一个缓冲区，生产者负责把数据放入到缓冲区中，消费者负责把缓冲区中的数据取出来；
两类角色：指的是生产者和消费者；
三种关系：三种关系分别指的是：消费者和消费者，生产者和生产者，生产者和消费者；其中消费者和消费者，生产者和生产者之间都属于竞争关系，生产者和消费者之间的关系相当于是一种食物链之间的依赖关系。

生产者和消费者模型的特点

首先，生产者只需要关心“仓库”，并不需要关心具体的消费者。
对于消费者而言，它不需要关心具体的生产者，它只需要关心这个“仓库”中还有没有东西存在。
生产者生产的时候消费者不能进行“消费”，消费者消费的时候生产者不能生产，相当于一种互斥关系，即生产者和消费者一次只能有一人能访问到“仓库”。
“仓库”为空时不能进行消费。
“仓库”满时不能进行生产。
final关键字

被final修饰的类不可以被继承
被final修饰的方法不可以被重写
被final修饰的变量不可以被改变，被final修饰不可变的是变量的引用，而不是引用指向的内容，引用指向的内容是可以改变的
抽象类和接口的对比

抽象类是用来捕捉子类的通用特性的。接口是抽象方法的集合。

从设计层面来说，抽象类是对类的抽象，是一种模版设计，接口是行为的抽象，是一种行为的规范。

相同点：

接口和抽象类都不能实例化
都位于继承的顶端，用于被其他实现或继承
都包含抽象方法，其子类都必须覆写这些抽象方法
不同点：

参数	抽象类	接口
访问修饰符	抽象类中的方法可以是任意访问修饰符	接口方法默认修饰符是public。并且不允许定义为private或者protected
多继承	一个类最多只能继承一个抽象类	一个类可以实现多个接口
Q：对象实例和对象引用有何不同？

对象实例存在堆内存中，对象引用存放在栈内存中；一个对象引用可以指向0个或1个对象（一根绳子可以不系气球，也可以系一个气球）；一个对象可以有n个引用指向它（可以用n条绳子系住一个气球）

Q：Java new一个对象的过程？

首先到常量池中找类的带路径全名，然后检查对应的字节码是否已被加载，解析，验证，初始化，如果没有先执行类加载过程(class.forname())。
类加载过程完成后，虚拟机会为对象分配内存。分配内存有两种方式，根据使用的垃圾收集器的不同使用不同的分配机制。
(1)指针碰撞
(2)空闲列表
设置对象头信息，如所属类，元数据信息，哈希码，gc分代年龄，等等。
调用对象的init()方法,根据传入的属性值给对象属性赋值。
在线程栈中新建对象引用，并指向堆中刚刚新建的对象实例。
Q：s+=1 和 s = s+1有区别吗？

如果s是short类型的话，s = s+1会报错，因为右边是int类型而左边是short类型，需要强制转换；而+=1不会报错因为隐含了强制类型转换

Q：String是最基本的数据类型吗？

不是。Java 中的基本数据类型只有 8 个 ：byte、short、int、long、float、double、char、boolean；除了基本类型（primitive type），剩下的都是引用类型（referencetype），Java 5 以后引入的枚举类型也算是一种比较特殊的引用类型。String底层就是一个char类型的数组。

Q：String真的是不可变的吗？

是的，String类利用了final修饰的char类型数组存储字符，对它进行任何操作，其实都是在创建一个新的对象，再把引用指向该对象。

Q：String str="i"与String str=new String("i")一样吗？

不一样，因为内存的分配方式不一样。String str="i"的方式，java 虚拟机会将其分配到常量池中；而 String str=new String(“i”) 则会被分到堆内存中。

Q：在使用 HashMap 的时候，用 String 做 key 有什么好处？

HashMap内部实现是通过key的hashcode来确定value的存储位置，因为字符串是不可变的，所以当创建字符串时，它的hashcode被缓存下来，不需要再次计算，所以相比于其他对象更快。

Q：String、StringBuffer和StringBuilder有什么区别？

String是不可变的，而StringBuilder和StringBuffer都继承自AbstractStringBuilder类，这两种对象都是可变的。
StringBuffer是线程安全的，而StringBuilder不是线程安全的

总结：如果要操作少量的数据用 = String；
单线程操作字符串缓冲区下操作大量数据 = StringBuilder
多线程操作字符串缓冲区下操作大量数据 = StringBuffer

Q：Integer a= 127 与 Integer b = 127相等吗？

是相等的。因为如果整型字面量的值在-128到127之间，那么自动装箱时不会new新的Integer对象，而是直接引用常量池中的Integer对象，超过范围 a1==b1的结果是false。

Q：Java 缓冲流 buffer 的用途和原理是什么？

基本原理：在创建流对象时，会创建一个内置默认大小的缓冲区数组，减少系统IO次数，从而提高读写效率

用途：字节输入输出缓冲流，用于缓冲数据，提高性能

多线程

Q：为什么需要多线程？（何时考虑使用多线程）

从用户的角度考虑，就是为了得到更好的系统服务；从程序自身的角度考虑，就是使目标能够尽可能快的完成，更有效的利用系统资源。
综合考虑，一般以下场合需要使用多线程：
1、程序包含复杂的计算任务时；
主要是利用多线程获取更多的CPU时间（资源）
2、处理速度较慢的外围设备
比如：打印时；再比如网络程序，涉及数据包的收发，时间因素不定。使用独立的线程处理这些任务，可使程序无需专门等待结果。
3、程序设计自身的需要
WINDOWS系统是基于消息循环的抢占式多任务系统，为使消息循环系统不至于阻塞，程序需要多个线程来共同完成某些任务

多线程的缺点：
1、如果有大量的线程，会影响性能，因为操作系统需要在它们之间切换
2、更多的线程需要更多的内存空间
3、线程中止需要考虑对程序运行的影响
4、通常块模型数据是在多个线程间共享的，需要防止线程死锁情况的发生。

动态代理

概念：代理是一种常用的设计模式，其目的就是为其他对象提供一个代理以控制对某个对象的访问。代理类负责为委托类预处理消息，过滤消息并转发消息，以及进行消息被委托类执行后的后续处理。

JDK动态代理的方法最大的弊端是：被代理的类需要实现某一个接口，如果一个类没有实现任何接口的话，就无法被代理。

设计模式

单例模式

将对象初始化函数设置成private，使得外部无法使用new方法来生成实例，只能使用object.getInstance()
观察者模式

工厂模式

抽象工厂

Spring IOC

单例模式

保证一个类在内存中只能有一个对象。

思路：

1）如果其他程序能够随意用 new 创建该类对象，那么就无法控制个数。因此，不让其他程序用 new 创建该类的对象。

2）既然不让其他程序 new 该类对象，那么该类在自己内部就要创建一个对象，否则该类就永远无法创建对象了。

3）该类将创建的对象对外(整个系统)提供，让其他程序获取并使用。

饿汉式：
一上来我就把对象给你 new 好了，你来了直接就可以拿去“吃”了

懒汉式：
（要是有人问单例的延迟加载方式指的就是这种方式）
一开始我就不给你 new 对象，你来找我，我在给你创建一个对象

懒汉式有一个缺点，就是在多线程中使用的时候，可能会创建多个实例对象，比如，线程1来调用 getInstance() 方法，判断了 s==null，然后线程1由于未知的原因阻塞了，线程2再来调用 getInstance() 方法，判断 s==null ，线程2就创建了一个对象，这时候线程1又运行了，那么线程1就会创建一个对象~这样就会造成多个对象~

懒汉式的线程优化——加一个锁

HashMap

HashMap是基于哈希表的Map接口的实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。另外，HashMap是非线程安全的，也就是说在多线程环境下，可能会存在问题。
HashMap一种常见的实现方法是——拉链法，我们可以理解为“链表的数组”。

HashMap的底层是将key映射成hashcode，运用到MD5算法

java1.8以后新增了红黑树，一旦链表长度大于等于8，则转红黑树

Q：为什么链表转红黑树的阈值设置为8？

A：这是一个统计规律，主要是根据hashcode的Poisson柏松分布，并且阈值必须为2的幂次方的要求所取得的合适的值

Q：HashMap什么情况下会扩容？

HashMap扩容的条件：

新建的HashMap容量为DEFAULT_INITIAL_CAPACITY=16，

系数DEFAULT_LOAD_FACTOR=0.75，
HashMap 中的元素数量大于阈值 threshold。当第一次扩容时目前的元素数量>=DEFAULT_INITIAL_CAPACITY*DEFAULT_LOAD_FACTOR时，会将HashMap的容量扩大一倍（x2）,一次类推每次加入数据时都会判断当前的元素数与容量的占比。
最大个数为Integer.MAX_VALUE即2147483648。
造成HashMap扩容的操作：

putMapEntries（）：插入
putVal（）
put（）
treeifyBin（）
merge（）：合并
Q：hashcode 和 equals 方法的联系？

首先equals与hashcode间的关系是这样的：

1、如果两个对象相同（即用equals比较返回true），那么它们的hashCode值一定要相同；

2、如果两个对象的hashCode相同，它们并不一定相同(即用equals比较返回false)  

自我的理解：由于为了提高程序的效率才实现了hashcode方法，先进行hashcode的比较，如果不同，那没就不必在进行equals的比较了，这样就大大减少了equals比较的次数，这对比需要比较的数量很大的效率提高是很明显的，一个很好的例子就是在集合中的使用；

我们都知道java中的List集合是有序的，因此是可以重复的，而set集合是无序的，因此是不能重复的，那么怎么能保证不能被放入重复的元素呢，但靠equals方法一样比较的话，如果原来集合中以后又10000个元素了，那么放入10001个元素，难道要将前面的所有元素都进行比较，看看是否有重复，欧码噶的，这个效率可想而知，因此hashcode就应遇而生了，java就采用了hash表，利用哈希算法（也叫散列算法），就是将对象数据根据该对象的特征使用特定的算法将其定义到一个地址上，那么在后面定义进来的数据只要看对应的hashcode地址上是否有值，那么就用equals比较，如果没有则直接插入，只要就大大减少了equals的使用次数，执行效率就大大提高了。继续上面的话题，为什么必须要重写hashcode方法，其实简单的说就是为了保证同一个对象，保证在equals相同的情况下hashcode值必定相同，如果重写了equals而未重写hashcode方法，可能就会出现两个没有关系的对象equals相同的（因为equal都是根据对象的特征进行重写的），但hashcode确实不相同的

HashTable

ConcurrentHashMap

Q：为何会出现ConcurrenHashMap？

HashTable在高并发场景下性能低下；
HashMap不是线程安全的容器；
同步包装器虽然使用同步方法快提升了部分性能，但是还是不适合高并发场景下的性能需求；
Q：ConcurrentHashMap如何保证线程安全？

java7:使用的是分离锁（segment）实际上是一种再入锁（RetrantLock）来保证线程安全；
segment的数量是由concurrentLevel决定的，默认值是16；

Q：ConcurrentHashMap怎么保证写数据安全的呢？

首先说一下如何保证线程安全吧，ConcurrentHashMap它采用的是Synchronized来锁桶里面的头节点，来保证桶内的写操作是线程安全的；再假如说，slot里面是空的（也就是没有头节点，没有数据），这个时候它是依赖CAS来实现线程安全的。线程会使用CAS的方式向slot里面写头节点数据，成功的话它就返回，失败的话，就说明有其他线程竞争到了这个slot的位置了，当前线程它只能重新执行写逻辑，再次路由到这个slot位置的时候呢，slot应该就已经有值了（其他线程CAS写成功过），当前线程就会采用Synchronized锁桶内的头节点，来保证写线程安全，这样的话桶内肯定就是串行的了。

Q：JDK8中hash寻址算法是怎么样的？

是利用当前key对应的hashcode，通过与运算，假设数组长度为n，则使用n-1和hashcode做与运算代替取模运算。

Q：为什么使用与运算而不用除法取余数？

对于现代的处理器来说，除法和求余数（模运算）是最慢的动作
数学公式：
a % b = ( b -1 ) & a， 当b是2的指数时，等式成立
Q：JDK8中用到的哈希算法是怎么样的？

通常需要把key的hashcode右移16位然后和他本身进行异或运算，得到的结果再和n-1进行与运算（取模）最终得到key对应的index

Q：用到什么数据结构？
数组+链表+红黑树

Q：初始化长度是多少？
DEFAULT_CAPACITY = 16;

Q：什么时候会用链表？什么时候会用红黑树？
初始化都是链表，链表长度超过默认8位TREEIFY_THRESHOLD=8（binCount >= TREEIFY_THRESHOLD），该结点会转换为红黑树。

Q：相同hash值怎么处理？
链表：相同hash值，相同key选择性覆盖；相同hash值，不同key，新增node结点保存。
红黑树：相同hash值，相同key选择性覆盖；相同hash值，不同key，新增node结点保存。

Q：ConcurrentHashMap如何保证线程安全？
java7版本使用的是分离锁（segment）实际上是一种再入锁（RetrantLock）来保证线程安全；
java8中segment依然存在，不过不起结构上的作用，只起到保证序列化的兼容性。内部使用volatile来保证数据存储的可见性；利用CAS操作，在特定场景下进行无锁并发操作，内部的锁实际用的是syncronized；

Q：volatile和synchronized的区别？
1）volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
2）volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的
3）volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性
4）volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。
5）volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化

ConcurrentHashMap的put流程：

第一次插入时初始化数组table（为volatile修饰），其大小默认为16。插入元素时先获得键的hash值，然后找到数组索引插入，插入时先看数组是否为空。
为空：初始化table：先看sizeCtl是否为小于0，为-1则其他线程占有锁。不为则初始化其为-1，然后默认数组大小为16。sizeCtl为16*0.75。
然后判断数组第一个位置是否为空，
为空，采用casTab（）插入。
不为空，判断其hash是否为-1。为-1，判断是否在扩容，不是扩容直接返回table。
不为空：加锁：synchronized (f)
看是为链表还是红黑树，然后插入。头结点的hash>0，则为链表。

CAS（乐观锁）

synchronized是悲观锁，这种线程一旦得到锁，其他需要锁的线程就挂起的情况就是悲观锁
CAS操作的就是乐观锁，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，知道成功为止
红黑树题目：

AVL树即平衡二叉搜索树

红黑树性质：
1.每个结点或是红色的，或是黑色的
2.根节点是黑色的
3.每个叶结点（NIL）是黑色的
4.如果一个节点是红色的，则它的两个儿子都是黑色的
5.对于每个结点，从该结点到其叶子结点构成的所有路径上的黑结点个数相同

和AVL树（平衡二叉搜索树）的比较：
AVL树是一棵严格的平衡树，它所有的子树都满足二叉平衡树的定义。因此AVL树高被严格控制在XXX，因此AVL树的查找比较高效。但AVL树插入、删除结点后旋转的次数比红黑树多。
红黑树用非严格的平衡来降低插入删除时旋转的次数。红黑树能够以O(log2 n)的时间复杂度进行搜索、插入、删除操作。此外，由于它的设计，任何不平衡都会在三次旋转之内解决。因此，如果业务中查找远远多于插入、删除，那选AVL树；如果查找、插入、删除频率差不多，那么选择红黑树。

红黑树能够保证在最坏情况下，基本的动态几何操作的时间均为O(lgn)

JVM
JVM内存结构

按照线程来分可以分为线程共享区和线程独占（隔离）区。线程共享区包括java堆、方法区，线程独占区包括虚拟机栈、本地方法栈和程序计数器。其中方法区它是Java虚拟机的一个模型规范，具体实现的话是元空间和永久代，永久代是JDK1.7的，1.8以后就被移除了，它就变成元空间了，元空间是主要分布在计算机内存的，它是脱离了Java虚拟机内存的，它是独立存在的。

深拷贝与浅拷贝

浅拷贝（shallowCopy）只是增加了一个指针指向已存在的内存地址；

深拷贝（deepCopy）是增加了一个指针并且申请了一个新的内存，使这个新增加的指针指向这个新的内存；

使用深拷贝的情况下，释放内存的时候不会因为出现浅拷贝时释放同一个内存的错误

堆和栈的区别

物理地址上：

堆的物理地址分配对象是不连续的。因此性能会慢些。在GC的时候也要考虑到不连续的分配，所以有各种算法。比如，标记-消除，复制，标记-压缩，分代（即新生代使用复制算法，老年代使用标记-压缩）

栈使用的是数据结构中的栈，先进后出的原则，物理地址分配是连续的。所以性能快。

内存区别：

堆因为不连续，所以分配的内存是在运行期确认的，因此大小不固定。一般堆大小远远大于栈

栈是连续的，所以分配的内存大小要在编译期就确认，大小是固定的。

存放的内容：

堆存放的是对象的实例和数组。因此该区更关注数据的存储。

栈存放局部变量，操作数栈，返回结果。该区更关注的是程序方法的执行。

PS：静态变量放在方法区，静态的对象还是放在堆

程序可见度：

堆对于整个应用程序都是共享、可见的

栈只对于线程是可见的。所以也是线程私有。它的生命周期和线程相同。

Java对象创建的过程

对象创建方式

调用构造函数：使用new关键字、使用Class的newInstance方法、使用Constructor类的newInstance方法

没有调用构造函数：使用clone方式、使用反序列化

对象创建的主要流程：

虚拟机遇到一条new指令时，先检查常量池是否已经加载相应的类，如果没有则必须先执行相应的类加载。类加载通过后，接下来分配内存。若Java堆中内存是绝对规整的，使用“指针碰撞”方式分配内存；如果不是规整的，就从空闲列表中分配，称之为“空闲列表”方式。划分内存时还需要考虑一个并发问题，也有两种方式：CAS同步处理或者本地线程分配缓冲（Thread Local Allocation Buffer，TLAB）。然后内存空间初始化操作，接着做一些必要的对象设置，最后执行init方法。

分配内存的两种方式：

指针碰撞：如果Java堆的内存是规整，即所有用过的内存放在一边，而空闲的的放在另一边。分配内存时将位于中间的指针指示器向空闲的内存移动一段与对象大小相等的距离，这样便完成分配内存工作。
空闲列表：如果Java堆的内存不是规整的，则需要由虚拟机维护一个列表来记录那些内存是可用的，这样在分配的时候可以从列表中查询到足够大的内存分配给对象，并在分配后更新列表记录。
处理并发安全的两种方式：

对分配内存空间的动作进行同步处理（采用 CAS + 失败重试来保障更新操作的原子性）；
把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在 Java 堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer, TLAB）。哪个线程要分配内存，就在哪个线程的 TLAB 上分配。只有 TLAB 用完并分配新的 TLAB 时，才需要同步锁。通过-XX:+/-UserTLAB参数来设定虚拟机是否使用TLAB。
Java内存泄漏问题

内存泄漏是指不再被使用的对象或者变量一直被占据在内存中。理论上来说，Java是有GC垃圾回收机制的，也就是说，不再被使用的对象，会被GC自动回收掉，自动从内存中清除。

Q：Java会存在内存泄漏吗？请简单描述

存在内存泄漏，原因是：长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄漏，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这就是java中内存泄漏发生的场景。

Java 中垃圾回收机制

Q：简述Java垃圾回收（GC）机制？

在java中，程序员是不需要显式地去释放一个对象的内存的，而是有虚拟机自行执行。在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫描那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收。

java中的对象由于垃圾回收机制而不再有“作用域”的概念，只有引用的对象才有“作用域”。

Q：垃圾回收器的基本原理是什么？

通常，GC采用有向图的方式记录和管理堆（heap）中的所有对象。通过这种方式确定哪些对象是“可达的”，哪些对象是“不可达的”。当GC确定一些对象为“不可达”时，GC就有责任回收这些内存空间。

Q：有什么办法可以主动通知虚拟机进行垃圾回收？

程序员可以手动执行System.gc()，通知GC运行，但是Java语言规范并不保证GC一定会执行。

Java引用类型

强引用：发生gc的时候不会被回收。
软引用：有用但不是必须的对象，在发生内存溢出之前会被回收。
弱引用：有用但不是必须的对象，在下一次GC时会被回收
虚引用（幽灵引用/幻影引用）：无法通过虚引用获得的对象，用 PhantomReference 实现虚引用，虚引用的用途是在 gc 时返回一个通知。
判断对象是否需要回收的方法即确定对象是否存活，常用两种算法分析对象是否存活：引用计数算法和可达性分析算法。

1、引用计数算法

1）给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加1；
2）当引用失效时，计数器值就减1；
3）任何时刻计数器为0的对象就是不可能再被使用的；

算法优点：实现简单，判断效率高；

算法缺点：很难解决对象之间相互循环引用的问题。所以主流的虚拟机里没有选用引用计数算法来管理内存的。

2、可达性分析算法

通过一系列的称为“GC Roots”(所谓“GC roots”，或者说tracing GC的“根集合”，就是一组必须活跃的引用)的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为GC Roots引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。



可达性分析算法判定对象是否可以回收的图例中，绿色部分为仍然存活的对象，黄色部分判定可回收的对象。黄色部分object5、object6、object7虽然相互关联，但是它们到GC Roots是不可达的，也就是没有与GC Roots建立引用链，所以它们将被判定为是可以回收的对象。

在Java语言中，可以作为GC Roots的对象包括下面几种：
1）虚拟机栈（栈帧中的本地变量表）中引用的对象。
2）方法区中静态属性引用的对象。
3）方法区中常量引用的对象，在jdk7后被移到堆中。
4）本地方法栈中JNI(即一般说的Native方法)引用的对象。

算法优点：
更加精确和严谨，可以分析出循环数据结构相互引用的情况；

算法缺点：
1）实现比较复杂；
2）需要分析大量数据，消耗大量时间；
3）分析过程需要GC停顿（引用关系不能发生变化），即停顿所有Java执行线程（称为"Stop The World"，是垃圾回收重点关注的问题）；

Q：JVM中的永久代会发生垃圾回收吗？

垃圾回收不会发生在永久代。如果永久代满了或者超过了临界值，会触发完全垃圾回收（Full GC）。如果查看垃圾收集器的输出信息，就会发现永久代也是被回收的。（Java8中已经移除了永久代，新加了一个叫做元数据区的native内存区）。

常见的GC回收算法：

1、标记-清除算法（Mark-Sweep算法）

标记-清除算法是最基础的收集算法。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。

这个算法如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。



算法缺点：
一是效率较低，标记和清除这两个步骤的效率都比较低。清除的效率低是因为需要扫描整个内存空间，逐个释放对象所占内存；
二是空间问题，标记清楚之后会产生大量不连续的内存碎片。空间碎片太多可能会导致在后面程序运行过程中，需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。

2、复制算法（Copying算法）

由于标记-清除算法效率较低以及产生内存碎片的问题，于是就产生了这个新的算法——复制算法。

这种算法原理就是将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块保留区上面，然后再把已使用过的内存空间一次清理掉。这样一来，仍然存活的对象被放进保留区，而垃圾对象也被释放了。同时，之前被使用的空间被清空后，成了新的保留区，而之前的保留区成了被使用的空间，就这样不断循环使用两个空间。



复制算法每次都是对整个半区进行内存回收，直接释放被使用的空间的全部内存，比一段一段释放的效率要高很多。同时，对象被复制到另外一个区域时，只要移动堆顶指针，按顺序分配内存对象即可被整齐地摆放，所以不会出现内存碎片。实现简单，运行高效。所以，复制算法的效率要远远高于标记—清除算法。

算法缺点：
每次都有一半的空间无法被使用，使得空间利用率很低。
所以我们在实际应用复制算法时会对其进行改进。

3、标记-整理算法（Mark-Compact算法）

标记-整理算法的标记过程仍与"标记-清除"算法一致，但后续步骤不是直接对可回收对象进行清理，而是让所有存活对象都向一端移动，直至这些对象相互靠拢，整齐排列，然后直接清理掉这之外的全部内存。



这个算法的关键就是整理步骤，这一步骤解决了内存碎片的问题。

JVM垃圾回收器

用于回收新生代的收集器：Serial、PraNew、Parallel Scanvenge（一般采用复制算法，优点效率高，缺点内存利用率低）

回收老年代的收集器：Serial Old、Parallel Old、CMS（一般采用标记-整理（压缩）算法）

用于回收整个Java堆的收集器：G1

分代垃圾回收器工作机制

分代回收器有两个分区：老生代和新生代，新生代默认的空间占比总空间的 1/3，老生代的默认占比是 2/3。

新生代使用的是复制算法，新生代里有 3 个分区：Eden、To Survivor、From Survivor，它们的默认占比是 8:1:1，它的执行流程如下：

把 Eden + From Survivor 存活的对象放入 To Survivor 区；
清空 Eden 和 From Survivor 分区；
From Survivor 和 To Survivor 分区交换，From Survivor 变 To Survivor，To Survivor 变 From Survivor。
Q：JVM 中内存模型是怎样的，简述新生代与老年代的区别？

Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存类似处理器的高速缓存。线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写在主内存中的变量。不同的线程之间的工作内存互不可见。

所谓的新生代和老年代是针对于分代收集算法来定义的，新生代又分为Eden和Survivor两个区。加上老年代就这三个区。数据会首先分配到Eden区 当中（当然也有特殊情况，如果是大对象那么会直接放入到老年代（大对象是指需要大量连续内存空间的java对象）。），当Eden没有足够空间的时候就会 触发jvm发起一次Minor GC。如果对象经过一次Minor GC还存活，并且又能被Survivor空间接受，那么将被移动到Survivor空 间当中。并将其年龄设为1，对象在Survivor每熬过一次Minor GC，年龄就加1，当年龄达到一定的程度（默认为15）时，就会被晋升到老年代 中了，当然晋升老年代的年龄是可以设置的。
其实新生代和老年代就是针对于对象做分区存储，更便于回收等等

Minor GC 是指发生在新生代的 GC，因为 Java 对象大多都是朝生夕死，所有 Minor GC 非常频繁，一般回收速度也非常快；
Major GC/Full GC 是指发生在老年代的 GC，出现了 Major GC 通常会伴随至少一次 Minor GC。Major GC 的速度通常会比 Minor GC 慢 10 倍以上。
Java类加载过程

Q：简述java类加载机制？

虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、解析和初始化，最终形成可以被虚拟机直接使用的java类型。

Q：描述一下JVM加载Class文件的原理机制

Class装载方式有两种：

隐式装载，程序在运行过程中当碰到通过new等方式生成对象时，隐式调用类装载器加载对应的类到jvm中
显式装载，通过class.forname()（反射）等方法，显式加载需要的类
Java类的加载是动态的，它不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类完全加载到jvm中，至于其他类，则在需要的时候才加载。（为了节省内存开销）

四种类加载器

boostrapLoader：引导类加载器（加载java核心类库，无法被java程序直接饮用）
ExtClassLoader：拓展类加载器（加载java的扩展库）
SystemClassLoader：系统类加载器（加载java应用的类）
自定义加载器
Q：说一下类加载的执行过程？

类加载分为五个步骤：

加载：根据查找路径找到相应的class文件然后导入；
验证：检查加载的class文件的正确性；
准备：给类中的静态变量分配内存空间；
解析：虚拟机将常量池中的符号引用（一个标示）替换成直接引用（指向内存中的地址）；
初始化：对静态变量和静态代码块进行初始化工作
双亲委派机制

定义：如果一个类加载器收到了类加载的请求，它首先不会自己去加载这个类，而是把这个请求委派给父类加载器去完成，每一层的类加载器都是如此，这样所有的加载请求都会被传送到顶层的启动类加载器中，只有当父加载无法完成加载请求（它的搜索范围中没找到所需的类）时，子加载器才会尝试去加载类。

作用：1.防止加载同一个.class
2.保证核心.class不被篡改

JVM调优

调优工具

jconsole：用于对JVM中的内存、线程和类等进行监控；
jvisualvm：JDK自带的全能分析工具，可以分析：内存快照、线程快照、程序死锁、监控内存的变化、gc变化等。
Q：JVM调优的参数有哪些？

-Xms2g：初始化堆大小为2g；

-Xmxg：堆最大内存为2g；

微服务
rpc

序列化：protobuf

分布式

CAP理论：

对于一个分布式系统，不能同时满足以下三点：

一致性（Consistency）
可用性（Availablity）
分区容错性（Partition Tolerance）
为什么需要一致性？

数据不能存在单个节点（主机）上，否则可能出现单点故障。
多个节点（主机）需要保证具有相同的数据
什么是一致性算法？

一致性算法就是让数据保持一致，在分布式系统中，可以理解为多个节点中数据的值是一致的。
强一致性

说明：保证系统改变提交以后立即改变集群的状态。

相关模型算法：

Paxos
Raft（muti-paxos）
ZAB（muti-paxos）
主从同步复制（一致性很高但可用性很差，因为如果其中一个节点复制失败则master会阻塞，导致整个集群不可用）
多数派，每次写都保证写入大于N/2个节点，每次读保证从大于N/2个节点中读（在并发环境下，无法保证系统正确性，顺序非常重要）
弱一致性

说明：也叫最终一致性，系统不保证改变提交以后立即改变集群的状态，但是随着时间的推移最终状态是一致的。

相关模型算法：

DNS系统
Gossip协议
强一致性算法——Basic Paxos

角色介绍：

Client：系统外部角色，请求发起者。像民众
Propser：接受Client请求，向集群提出提议（propose）。并在冲突发生时，起到冲突调节的作用。像议员（替群众提出议案）
Acceptor（Voter）：提议投票和接收者，只有在形成法定人数（Quorum，一般即为majority多数派）时，提议才会最终被接受。像国会
Learner：提议接受者，backup备份，对集群一致性没什么影响。像记录员
Basic Paxos的问题：

难实现、效率低（2轮RPC）、活锁

Multi Paxos

新概念：Leader：唯一的propser，所有的请求都需经过此Leader

Raft

Dubbo

概念：基于Java的高性能rpc分布式服务框架

Q：dubbo支持的协议有哪些？推荐哪一种？

dubbo://(推荐)
rmi://
hessian://
http://
webservice://
thrift://
memcached://
redis://
rest://
Q：Dubbo需要Web容器吗？

不需要，硬要用Web容器只会增加复杂性浪费资源

Q：Dubbo内置了哪些服务容器？

Spring Container
Jetty Container
Log4j Container
Q：Dubbo里面有哪几种节点角色？

